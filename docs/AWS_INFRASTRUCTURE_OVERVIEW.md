# Forever Us â€“ Arquitetura AWS (MVP da LLM)

**Data:** 30/10/2025  
**Autor:** Leandro C. Azambuja  
**Projeto:** Forever Us â€“ Sistema de Legado Digital e SimulaÃ§Ã£o de Personalidade  

## VisÃ£o Geral / Overview

O **MVP do Forever Us** foi projetado para demonstrar a integraÃ§Ã£o de uma **LLM (Large Language Model)** hospedada na **AWS**, com foco em **baixo custo**, **escalabilidade** e **simplicidade operacional**.  
A arquitetura garante que o **frontend**, o **backend** e o **modelo de linguagem** se comuniquem de forma eficiente, segura e sem desperdÃ­cio de recursos.


The **Forever Us MVP** was designed to demonstrate the integration of a **Large Language Model (LLM)** hosted on **AWS**, focusing on **low cost**, **scalability**, and **operational simplicity**.
The architecture ensures that the **frontend**, **backend**, and **language model** communicate efficiently, securely, and without wasting resources.

---

## Estrutura da Arquitetura / Architecture Structure

```
[UsuÃ¡rio] 
   â†“
[CloudFront]
   â†“
[S3 (Frontend)]
   â†“ (via API JavaScript)
[API Gateway]
   â†“
[AWS Lambda â†” DynamoDB]
   â†“
[Bedrock (Mistral 7B)]
```

Essa topologia mostra o caminho completo de uma requisiÃ§Ã£o â€” desde o acesso do usuÃ¡rio atÃ© o processamento pelo modelo de linguagem e o retorno da resposta.

---

## Frontend

**ServiÃ§os:** `Amazon S3` | `Amazon CloudFront`  

- **S3 (Simple Storage Service)** hospeda o site estÃ¡tico, contendo arquivos HTML, CSS e JavaScript.  
  Ã‰ simples, seguro e de custo muito baixo.  
- **CloudFront** (opcional) distribui o conteÃºdo globalmente, reduzindo a latÃªncia e melhorando a performance.  

> O frontend Ã© a camada sempre ativa, com custo praticamente nulo.

---

## Backend

**ServiÃ§os:** `Amazon API Gateway` | `AWS Lambda` | `Amazon DynamoDB`

- **API Gateway** atua como porta de entrada das requisiÃ§Ãµes vindas do site, repassando-as com seguranÃ§a para o backend.  
- **AWS Lambda** processa cada requisiÃ§Ã£o sob demanda, conectando-se ao modelo e retornando a resposta ao usuÃ¡rio.  
  Ã‰ **serverless** e **paga-se apenas pelo uso efetivo**.  
- **DynamoDB** registra logs e histÃ³rico de conversas, garantindo persistÃªncia leve entre execuÃ§Ãµes.

> Essa camada Ã© responsÃ¡vel pela lÃ³gica do sistema e pela ponte entre o site e a LLM.

---

## LLM â€“ CÃ©rebro da AplicaÃ§Ã£o / Application Brain

**ServiÃ§o:** `Amazon Bedrock` (Modelo **Mistral 7B**)

- A camada de IA utiliza o **Amazon Bedrock**, serviÃ§o gerenciado da AWS que oferece acesso direto a modelos de linguagem de Ãºltima geraÃ§Ã£o.  
- O modelo **Mistral 7B** foi escolhido pelo equilÃ­brio entre custo e desempenho.  
- Caso o Bedrock nÃ£o esteja disponÃ­vel, o modelo pode ser executado em uma **instÃ¢ncia EC2** temporÃ¡ria, ativada apenas durante os testes.

> Essa camada Ã© o coraÃ§Ã£o do MVP, responsÃ¡vel por gerar respostas em linguagem natural.

---

## Monitoramento e Custos / Monitoring and Costs

**ServiÃ§os:** `Amazon CloudWatch` | `AWS Budgets`

- **CloudWatch** coleta mÃ©tricas, logs e monitora a saÃºde dos serviÃ§os.  
- **AWS Budgets** envia alertas quando o consumo se aproxima do limite de crÃ©ditos definido.  

> O objetivo Ã© garantir previsibilidade financeira e evitar custos desnecessÃ¡rios.

---

## EstratÃ©gia de Economia / Economic Strategy

1. **A IA (Bedrock/EC2)** sÃ³ Ã© ligada durante os testes.  
2. ApÃ³s o uso, Ã© desligada manualmente para evitar cobranÃ§as adicionais.  
3. **S3, Lambda e API Gateway** permanecem ativos, com custo quase nulo.  
4. **DynamoDB** usa o modo â€œsob demandaâ€, economizando leitura e escrita.

> Essa estratÃ©gia garante que o MVP possa ser testado continuamente sem exceder os crÃ©ditos AWS Educate/Restart.

---

## Fluxo de ComunicaÃ§Ã£o / Data Flow

```
1. O usuÃ¡rio acessa o site hospedado no **S3** (opcionalmente acelerado via **CloudFront**).  
2. Ao enviar uma mensagem, o **JavaScript** do frontend chama o **API Gateway**.  
3. O **API Gateway** repassa o pedido para uma **funÃ§Ã£o Lambda**.  
4. A **Lambda** envia a requisiÃ§Ã£o Ã  **LLM (Mistral 7B no Bedrock)** e armazena logs no **DynamoDB**.  
5. A resposta da LLM retorna pelo mesmo caminho atÃ© o navegador do usuÃ¡rio.
```

---

## ğŸ“Š MÃ©tricas Recomendadas / Recommended Metrics

```
- Disponibilidade da instÃ¢ncia de IA (Bedrock/EC2)  
- Tempo mÃ©dio de resposta (latÃªncia total)  
- Volume de requisiÃ§Ãµes processadas  
- Custo mensal total dos serviÃ§os  
- Logs de erro e uso de memÃ³ria via CloudWatch  
```

---

## PossÃ­veis ExtensÃµes / Future Enhancements

```
- Suporte a modelos multimodais (texto, voz, imagem)  
- Processamento assÃ­ncrono com SQS ou Step Functions  
- Uso de containers gerenciados (ECS ou EKS)  
- AutomaÃ§Ã£o do ciclo de inicializaÃ§Ã£o/desligamento da IA  
- Escalabilidade automÃ¡tica com base em demanda real  
```

---

## ConclusÃ£o / Conclusion

A arquitetura AWS do **Forever Us â€“ MVP da LLM** foi construÃ­da com base em trÃªs pilares:
**simplicidade, eficiÃªncia e economia**.  
Ela demonstra que Ã© possÃ­vel integrar um modelo de linguagem robusto em um ambiente cloud de baixo custo, mantendo seguranÃ§a, modularidade e possibilidade de expansÃ£o futura.


The AWS architecture of **Forever Us â€“ LLM MVP** was built on three pillars:
**simplicity, efficiency, and cost-effectiveness**.
It demonstrates that it is possible to integrate a robust language model into a low-cost cloud environment, while maintaining security, modularity, and the possibility of future expansion.


> â€œPequeno no custo, grande na ideia.â€ â€“ Filosofia do MVP Forever Us  
